# chirp‚Äëtranscript‚Äëtool  

> **TL;DR** ‚Äì Turn one or many plain‚Äëtext transcripts into natural‚Äësounding speech, clean the audio, and get timestamps ‚Äì all in a single command‚Äëline run.  

The tool stitches together four Google Cloud services such as Vertex‚ÄØAI Gemini, Cloud‚ÄØText‚Äëto‚ÄëSpeech‚ÄØ(Chirp‚ÄëHD‚Äë3), Cloud‚ÄØStorage (buckets) with two open‚Äësource libraries (ffmpeg, WhisperX) and a tiny CLI wrapper that handles flag parsing, cost reporting, and error handling.

---

**Disclaimer:**  
This code was writen as part of a learning project and is not a product software. By using it, modifying, or distributing this code, you acknowledge that you are solely responsible for all outcomes, consequences, and legal obligations arising from your actions. The author(s) and contributors provide no warranty or liability for any misuse, damages, or unintended effects resulting from the code.


## Table of Contents  

1. [Features](#features)  
2. [Presentation](#presentation)
3. [Architecture diagram](#architecture-diagram)  
4. [Prerequisites](#prerequisites)  
5. [Installation (UV)](#installation-uv)  
6. [Configuration (environment variables & `config.py`)](#configuration)  
7. [Command‚Äëline interface](#cli)  
8. [Pipeline walk‚Äëthrough](#pipeline-walk-through)  
9. [Examples](#examples)  
10. [Cost reporting](#cost-reporting)  
11. [Testing & debugging](#testing--debugging)  
12. [Troubleshooting](#troubleshooting)  
13. [Documentation / Bibliography](#bibliography)  
14. [License](#license)  

---

## Features  

| ‚úÖ | Description |
|----|-------------|
| **LLM‚Äëbased transcript polishing** | Optional Gemini‚ÄëPro‚ÄëPreview‚ÄØ3 pass that injects punctuation, pauses, and other ‚Äúhuman‚Äëlike‚Äù cues according to the **Chirp‚ÄëHD‚Äë3** documentation. |
| **Asynchronous TTS** | Sends asynchronously each (possibly tuned) transcript to **Google Cloud Text‚Äëto‚ÄëSpeech Long‚ÄëAudio** (Chirp‚ÄëHD‚Äë3) ‚Üí stores the result in a Cloud‚ÄØStorage bucket ‚Üí downloads locally. |
| **Silence removal** | One‚Äëliner ffmpeg `silenceremove` filter trims long pauses, making the final audio sound more natural. |
| **Word‚Äëlevel timestamps** | WhisperX (large‚Äëv2) produces timestamps (start/end) times for every spoken word. |
| **Batch processing** | Accept a single file, a directory of `.txt` files, or a raw prompt. |
| **Cost awareness** | Token‚Äëbased cost for Gemini, character‚Äëbased cost for Chirp‚ÄëHD‚Äë3, printed per‚Äëfile and overall. |
| **UV‚Äëbased packaging** | All dependencies declared in `pyproject.toml`; install with the fast, modern `uv` tool. |
| **Extensible flag parser** | `tools/flags_parser.py` validates mutual exclusivity (`--prompt` vs `--from‚Äëfile/--from‚Äëdir`). |

---

## Presentation

### Input text (from file)
```text
A lone astronomer set up a telescope on a desert ridge, hoping the clear night sky would reveal a secret.
When a faint flicker appeared, the instrument captured a pattern that spelled out a long‚Äëlost melody encoded in starlight.
The astronomer smiled, realizing the universe had been humming a song all along, waiting for someone to listen.
```

### Command
```bash
uv run main.py --from-file --tuning --verbose transcriptions/presentation_transcript.txt
```

### Log output
  
```
Initializing TTS client
Reading transcripts
Reading from file: transcriptions/presentation_transcript.txt
Loaded: transcriptions/presentation_transcript.txt
Reading Transcripts Done
Initializing LLM client
Setting LLM client for transcript tuning with model and getting response (gemini-3-pro-preview)
Got response - adding to list of responses

---Response---
A lone astronomer set up a telescope on a desert ridge, hoping the clear night sky would reveal a secret. When a faint flicker appeared... the instrument captured a pattern that spelled out a long‚Äëlost melody encoded in starlight. The astronomer smiled, realizing the universe had been humming a song all along - waiting for someone to listen.
---------


===OVERALL COST===
Prompt tokens: 2007.0 --- Cost: 0.00802800 $
Response tokens: 67.0 --- Cost: 0.00053600 $
Summary: 2074.0 tokens --- 0.00856400 $
===$$$===

Setting TTS client with model and storage client (Chirp - Sadaltager) and sending request.
Requesting Audio content to bucket: gs://bucket1/response_audio/presentation_transcript_20251219_143051.wav
Audio synthesized to GCS. Downloading: gs://bucket1/response_audio/presentation_transcript_20251219_143051.wav
Blob deleted: response_audio/presentation_transcript_20251219_143051.wav
Finished: presentation_transcript_20251219_143051.wav

===OVERALL COST===
Tokens: 343 --- Cost: 0.010290 $
===$$$===

Running ffmpeg remove silence
Removed silence and saved file to: edited_audio/presentation_transcript_20251219_143051.wav
Done cut silence. Files saved to directory: edited_audio
Loading WhisperX on cuda, batch_size = 8, compute_type = float16
Loading allign model
Transcribing audio
Cleaning memory - transcribe
Generating timestamps
Timestamps for file edited_audio/presentation_transcript_20251219_143051.wav generated.
Cleaning
Transcribing done file saved to timestamped_transcriptions/output.txt
```

### Tuned transcript (by Gemini-3-Pro-Preview)

```text
A lone astronomer set up a telescope on a desert ridge, hoping the clear night sky would reveal a secret.
When a faint flicker appeared... the instrument captured a pattern that spelled out a long‚Äëlost melody encoded in starlight.
The astronomer smiled, realizing the universe had been humming a song all along - waiting for someone to listen.
```

### Audio from TTS model (Chirp - voice Sadaltager)

üéµ [Click here to listen to the audio player](https://archbober.github.io/chirp-transcript-tool/audio_response.html)

### Audio after removing silence

üéµ [Click here to listen to the audio player](https://archbober.github.io/chirp-transcript-tool/audio_edit.html)

### Transcript with timestamps from file (per word for now in List[dict[str,str]] form)
```
[{'word': 'A', 'start': np.float64(0.031), 'end': np.float64(0.573)}, {'word': 'lone', 'start': np.float64(0.593), 'end': np.float64(0.934)}, ... -> ...  {'word': 'listen.', 'start': np.float64(19.219), 'end': np.float64(19.66)}]
```

or if srt file generated:

```
1
00:00:00,000 --> 00:00:03,722
A lone astronomer set up a telescope on a desert ridge, hoping the

2
00:00:03,802 --> 00:00:05,588
clear night sky would reveal a secret.

3
00:00:05,267 --> 00:00:09,179
When a faint flicker appeared, the instrument captured a pattern that

4
00:00:09,259 --> 00:00:12,128
spelled out a long-lost melody encoded in starlight.

5
00:00:11,667 --> 00:00:15,840
The astronomer smiled, realizing the universe had been humming a song

6
00:00:15,881 --> 00:00:18,207
all along, waiting for someone to listen.
```

---

## Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Input (txt / prompt)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   read_transcripts  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Is LLM tuning enabled? (‚Äì‚Äëtuning)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
   Yes  ‚ñº                       ‚ñº   No
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ      llm()          ‚îÇ   ‚îÇ (skip tuning step)  ‚îÇ
 ‚îÇ(Gemini‚ÄëPro‚ÄëPreview3)‚îÇ   ‚îÇ                     ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                         ‚îÇ
         ‚ñº                         ‚îÇ
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
 ‚îÇ  Async  tts_chirp() ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
 ‚îÇ (Google TTS ‚Äì Chirp)‚îÇ   
 ‚îÇ  ‚Üí upload to GCS    ‚îÇ   
 ‚îÇ      (bucket)       ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
         ‚îÇ                         
         ‚ñº                         
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   
 ‚îÇ       Async         ‚îÇ
 ‚îÇ Download from GCS   ‚îÇ   
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò 
         ‚îÇ                         
         ‚ñº                         
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  
 ‚îÇ   ffmpeg_cutter()   ‚îÇ  
 ‚îÇ (remove long pauses)‚îÇ   
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   
         ‚îÇ     
         ‚ñº     
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ stt_timestamps()    ‚îÇ   
 ‚îÇ     WhisperX        ‚îÇ
 ‚îÇ    word‚Äëlevel       ‚îÇ
 ‚îÇ    timestamps       ‚îÇ   
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   
 ```

 ## Prerequisites  

| Item | Minimum version / notes |
|------|------------------------|
| **Python** | 3.13 (declared in `pyproject.toml`) |
| **UV** | `uv >=0.4` ‚Äì the recommended installer for the project |
| **ffmpeg** | Must be on the system `$PATH` (`ffmpeg -version` works) |
| **GPU (optional)** | CUDA‚Äëenabled GPU for WhisperX speed‚Äëup; otherwise CPU fallback works (slower) |
| **Google Cloud project** | Vertex‚ÄØAI, Cloud‚ÄØStorage, Cloud‚ÄØText‚Äëto‚ÄëSpeech APIs enabled |
| **Service‚Äëaccount JSON** | With roles `aiplatform.user`, `storage.objectAdmin`, `texttospeech.admin` |

---

## Installation (UV)  

```bash
# 1Ô∏è‚É£ Clone the repo
git clone https://github.com/ArchBober/chirp-transcript-tool.git
cd chirp-transcript-tool

# 2Ô∏è‚É£ Install UV (if you don‚Äôt have it yet)
curl -LsSf https://astral.sh/uv/install.sh | sh

# 3Ô∏è‚É£ Create an isolated environment and install deps
uv venv .venv               # creates .venv/
source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 4Ô∏è‚É£ Install the package (reads pyproject.toml)
uv sync                     # resolves & installs all dependencies
```

> **Why UV?**  
> UV resolves the dependency graph **much faster** than `pip` and writes a lockfile (`uv.lock`) that guarantees reproducible builds. It also respects the `[project]` table from `pyproject.toml`, so you don‚Äôt need a separate `requirements.txt`.

## Configuration  

### Environment variables (`.env`)  

Create a file named `.env` in the repository root:

```dotenv
VERTEX_AI_API_KEY=<your‚Äëvertex‚Äëapi‚Äëkey>
SECRET_JSON_FILEPATH=/absolute/path/to/service-account.json
BUCKET_NAME=<your‚Äëgcs‚Äëbucket>
```

The script loads these with `python-dotenv`.  

### `config.py` (already shipped)  

| Constant | Meaning |
|----------|---------|
| `TTS_TEXT_FILE` | Default transcript used when no file flag is supplied. |
| `OUTPUT_AUDIO_DIR` / `EDITED_AUDIO_DIR` | Where raw and cleaned audio are stored locally. |
| `SPEAKING_RATE` | Default 1.0√ó (range 0.5‚Äë2.0). |
| `TTS_VOICE` | `"Sadaltager"` ‚Äì a Chirp‚ÄëHD‚Äë3 voice. |
| `LANGUAGE` | `"en‚ÄëUS"` ‚Äì language code for TTS. |
| `LLM_MODEL` | `"gemini-3-pro-preview"` ‚Äì the Gemini model used for tuning. (can be changed to cheaper one model) |
| `LLM_CHIRP_PROMPT` | Prompt that injects the **Chirp‚ÄëHD‚Äë3** scripting guidelines (see `descriptions/prompt_chirp_doc.py` and `config.py`). |
| `LLM_INPUT_TOKEN_PRICE`, `LLM_OUTPUT_TOKEN_PRICE`, `TTS_CHIRP_TOKEN_PRICE` | Pricing constants (USD per‚ÄØM tokens/characters). Update them if Google changes its rates. |
| `SRT_MAX_CHARS` | Max characters for new line srt generation. |
| `SRT_MAX_GAP` | Max time before new line in srt generation |

### Prompt documentation (`descriptions/prompt_chirp_doc.py` && `config.py`)  

Contains the full ‚ÄúScripting and prompting tips‚Äù you posted ‚Äì the LLM uses this to add natural‚Äëspeech cues without altering the original meaning.

## Command‚Äëline interface  

Run the entry point with `uv run main.py`. Flags are defined in `tools/flags_parser.py`.

| Flag | Alias | Description |
|------|-------|-------------|
| `--verbose` | ‚Äì | Print detailed progress and cost info. |
| `--cost-single` | ‚Äì | Show per‚Äëfile TTS cost. |
| `--prompt` | ‚Äì | First positional argument is treated as a raw prompt (no file reading). |
| `--tuning` | ‚Äì | Enable the Gemini LLM step; feed transcripts straight to TTS. |
| `--bucket‚Äëpreserve` | ‚Äì | Keep the temporary audio object in Cloud‚ÄØStorage after download. |
| `--from‚Äëfile` | ‚Äì | Load a **single** transcript file (default path or `TTS_TEXT_FILE`). |
| `--from‚Äëdir` | ‚Äì | Load **all** `.txt` files from the supplied directory. |
| `--help` | ‚Äì | Show the help description (`HELP_DESCRIPTION`). |
| `positional` | ‚Äì | Remaining arguments ‚Äì either the prompt text (`--prompt`) or the path(s) for `--from‚Äëfile/--from‚Äëdir`. |

**Mutual exclusions** (enforced by the parser):

* `--prompt` cannot be combined with `--from‚Äëfile` or `--from‚Äëdir`.  
* `--from‚Äëfile` and `--from‚Äëdir` cannot be used together.

## Pipeline walk‚Äëthrough  

1. **Parse flags** ‚Äì `tools/flags_parser.parse_flags()` validates the command line.  
2. **Read transcripts** ‚Äì `tools/read_transcripts.py` loads one file or an entire directory into a `Dict[str,str]`.  
3. **LLM tuning (optional)** ‚Äì `model_tools/llm.py` sends each transcript to Gemini (`genai.Client`). The system prompt (`LLM_CHIRP_PROMPT`) forces the model to only add punctuation/pauses/IPA tags described in the Chirp documentation.  
4. **Asynchronous TTS** ‚Äì `model_tools/tts_chirp.py`  
   * Calls `texttospeech.TextToSpeechLongAudioSynthesizeAsyncClient` with the refined text.  
   * Stores the generated WAV in the bucket (`gs://<BUCKET>/<OUTPUT_AUDIO_DIR>/‚Ä¶`).  
   * Downloads the file locally, optionally deleting the bucket object (`--no‚Äëbucket‚Äëpreserve`).  
5. **Silence removal** ‚Äì `tools/ffmpeg_cutter.py` runs `ffmpeg -af silenceremove=stop_periods=-1:stop_duration=0.2:stop_threshold=-40dB` removing silence longer than 0.2s and quiter than -40 dB (if those parameters are not changed by user).  
6. **Timestamp extraction** ‚Äì `model_tools/stt.py` loads WhisperX (large‚Äëv2) on the cleaned audio, aligns word‚Äëlevel timestamps, and writes them to `timestamped_transcriptions/output.txt`. Model can be changed. Also this library is very problematic so its worth to look on whisperx issue page if there will be some problems with environment/downloading etc.  

All heavy‚Äëweight I/O (bucket upload/download, TTS requests) is performed **asynchronously** with `asyncio.gather`, dramatically reducing total runtime for multi‚Äëfile batches (if not async it would do 1 file at a time which is quite long especially if many heavy inputs are delivered). That means max time waiting for TTS execution = largest file. 

## Examples  

### 3Ô∏è1Ô∏è‚É£ Using a file with not preserving copy on bucket and skipping tuning (skip LLM)  

```bash
uv run main.py \
    --from-file \
    --no-tuning ./script.txt
```

### 1Ô∏è2Ô∏è‚É£ Prompt ‚Üí LLM ‚Üí TTS ‚Üí Clean ‚Üí Timestamps  (with preserving it in bucket)

```bash
export VERTEX_AI_API_KEY=abcd123...890xyz
export SECRET_JSON_FILEPATH=$HOME/gcloud/key.json
export BUCKET_NAME=chirp-audio-bucket

uv run main.py \
    --prompt \
    --verbose \
    --tuning \
    --bucket-preserve \
    "What is lorem ipsum."

```

**What you get**

* `response_audio/name_<timestamp>.wav` ‚Äì raw Chirp synthesis.  
* `edited_audio/name_<timpestamp>.wav` ‚Äì silence‚Äëremoved version.  
* `timestamped_transcriptions/output.txt` ‚Äì JSON‚Äëlike list of `{word,start,end}`. (for now later add more options/ better option to save timestamps)

### 2Ô∏è3Ô∏è‚É£ Batch directory

```bash
uv run main.py \
    --from-dir \
    --cost-single ./my_transcripts

```

Processes every `*.txt` under `./my_transcripts`, prints per‚Äëfile TTS cost, and leaves the intermediate objects in the bucket (useful for later inspection).


## Cost reporting  

When `--verbose` (or `--cost-single`) is active the script prints three sections:

| Section | What is shown |
|---------|---------------|
| **LLM cost** | `prompt tokens √ó LLM_INPUT_TOKEN_PRICE` and `response tokens √ó LLM_OUTPUT_TOKEN_PRICE`. |
| **TTS cost** | `character count √ó TTS_CHIRP_TOKEN_PRICE`. |
| **Overall** | Sum of the above for the whole run. |

The numbers are **USD** (based on the constants in `config.py`). Adjust the constants if Google updates its pricing.

## Troubleshooting  

| Symptom | Likely cause | Fix |
|---------|--------------|-----|
| `ffmpeg: command not found` | ffmpeg not installed or not on `$PATH`. | Install via `apt-get install ffmpeg`, `brew install ffmpeg`, or download from https://ffmpeg.org/. |
| `google.api_core.exceptions.PermissionDenied` | Service‚Äëaccount lacks required IAM roles. | Grant `roles/aiplatform.user`, `roles/texttospeech.admin`, `roles/storage.objectAdmin` to the service account. |
| `Operation timed out` while waiting for TTS | Very long transcript (>‚ÄØ50‚ÄØk characters) or network latency. | Split the transcript into smaller chunks (‚â§‚ÄØ5000‚ÄØchars) before calling `tts_chirp()` or set higher timeout in tts_chrip.py ex. -> await operation.result(timeout=600). |
| WhisperX runs on CPU and is extremely slow | No CUDA device detected. | Install CUDA drivers and the matching `torch` wheel ex. -> (`uv add torch --extra-index-url https://download.pytorch.org/whl/cu121`). But for sanity its worth checking whisperx repository for solutions. |
| Empty `output.txt` after STT | Audio file never downloaded or corrupted. | Verify that `ffmpeg_cutter` produced a non‚Äëzero‚Äësize WAV; re‚Äërun with `--verbose` to see the download URI. |
| `--prompt` and `--from-dir` used together ‚Üí script exits | Parser correctly aborts. | Choose one mode only ‚Äì either a raw prompt or a directory of files. |

## Bibliography  

| # | Resource | Link |
|---|----------|------|
| 1 | **Google Vertex AI ‚Äì Gemini Pro Preview** (LLM used for transcript polishing) | <https://docs.cloud.google.com/vertex-ai/docs/start/introduction-unified-platform> |
| 2 | **Google Cloud Text‚Äëto‚ÄëSpeech ‚Äì Chirp‚ÄØHD‚ÄØ3** (high‚Äëquality neural voice) | <https://docs.cloud.google.com/text-to-speech/docs/chirp3-hd> |
| 3 | **Google Cloud Storage** (temporary bucket for long‚Äëaudio synthesis) | <https://docs.cloud.google.com/storage/docs> |
| 4 | **ffmpeg ‚Äì silenceremove filter** (removing long pauses) | <https://ffmpeg.org/ffmpeg-filters.html#silenceremove> |
| 5 | **WhisperX ‚Äì word‚Äëlevel timestamps** (open‚Äësource speech‚Äëto‚Äëtext) | <https://github.com/m-bain/whisperX> |
| 6 | **UV ‚Äì a fast Python package manager** | <https://github.com/astral-sh/uv> |
| 7 | **python‚Äëdotenv** (loading `.env` files) | <https://pypi.org/project/python-dotenv/> |
| 8 | **Google‚ÄëGenAI Python SDK** (client for Gemini) | <https://pypi.org/project/google-genai/> |
| 9 | **Google‚ÄëCloud‚ÄëText‚Äëto‚ÄëSpeech Python client** | <https://pypi.org/project/google-cloud-texttospeech/> |
|10| **Google‚ÄëCloud‚ÄëStorage Python client** | <https://pypi.org/project/google-cloud-storage/> |
|11| **OpenAI‚ÄëWhisper** (fallback STT model used by WhisperX) | <https://github.com/openai/whisper> |
|12| **Prompt engineering guide for Chirp** (the large block you supplied) | *Embedded in `descriptions/prompt_chirp_doc.py`* |

## License  

This project is released under the **MIT License**. See the `LICENSE` file for full terms.

---  

*Enjoy turning text into natural‚Äësounding audio!* üöÄ